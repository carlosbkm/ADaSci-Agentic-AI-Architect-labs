{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlosbkm/ADaSci-Agentic-AI-Architect-labs/blob/main/Introduction_to_CrewAI_and_its_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi Agent Customer Support System"
      ],
      "metadata": {
        "id": "W0yJHel43nRO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this walkthrough, we‚Äôll demonstrate how to build a multi-agent support workflow using CrewAI, a lightweight framework for designing collaborative AI systems.\n",
        "You‚Äôll learn how to:\n",
        "\n",
        "\n",
        "*   Define role-specific agents with goals, backstories, and communication styles\n",
        "*   Set up tools for agents to access external knowledge and verify facts\n",
        "*   Orchestrate structured task pipelines with delegation and review flows\n",
        "*   Use CrewAI memory to enable more informed interactions across tasks\n",
        "\n",
        "\n",
        "By the end, you‚Äôll have a fully functional AI-powered support team that can answer customer questions, self-check for quality, and deliver a polished final response ‚Äî all within a transparent, traceable multi-agent system.\n"
      ],
      "metadata": {
        "id": "bcI0vxcxEr5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29 huggingface_hub"
      ],
      "metadata": {
        "id": "puuBzWmI4AFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install crewai crewai_tools langchain_community huggingface_hub"
      ],
      "metadata": {
        "id": "bHGCf20WTj9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "h08KkQ7iF87s"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew"
      ],
      "metadata": {
        "id": "m4jFIQszF9FD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, os\n",
        "from google.colab import userdata\n",
        "\n",
        "hf_token = userdata.get(\"HF_API_TOKEN\")\n",
        "if not hf_token:\n",
        "    raise ValueError(\"‚ùå Please set HF_API_TOKEN in Runtime > Variables\")\n",
        "\n",
        "def hf_generate(prompt,\n",
        "                # CHANGE: Use a known, reliably free model like 'gpt2'\n",
        "                model=\"gpt2\",\n",
        "                temperature=0.7,\n",
        "                max_new_tokens=512):\n",
        "    \"\"\"Query the free Hugging Face hosted inference API directly.\"\"\"\n",
        "    # The URL structure remains the same\n",
        "    url = f\"https://api-inference.huggingface.co/models/{model}\"\n",
        "    headers = {\"Authorization\": f\"Bearer {hf_token}\"}\n",
        "    payload = {\n",
        "        \"inputs\": prompt,\n",
        "        \"parameters\": {\"temperature\": temperature,\n",
        "                       \"max_new_tokens\": max_new_tokens},\n",
        "    }\n",
        "    r = requests.post(url, headers=headers, json=payload)\n",
        "    r.raise_for_status() # This will now likely succeed\n",
        "    data = r.json()\n",
        "\n",
        "    # Note: GPT2 is a Causal LM, so the output may need different handling\n",
        "    # depending on the full response structure, but this general function\n",
        "    # should still extract the generated text.\n",
        "    if isinstance(data, list):\n",
        "        # For text generation models, the response is often a list of one dict\n",
        "        return data[0].get(\"generated_text\", \"\")\n",
        "    return data.get(\"generated_text\", \"\")\n",
        "\n",
        "# üîç quick test\n",
        "print(hf_generate(\"Explain briefly what Reinforcement Learning is.\"))"
      ],
      "metadata": {
        "id": "IRMblc9EF9Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Role playing, Focus and coperation**"
      ],
      "metadata": {
        "id": "7PzhTI3_G7IH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "support_agent = Agent(\n",
        "    role=\"Senior Support Representative\",\n",
        "\tgoal=\"Be the most friendly and helpful \"\n",
        "        \"support representative in your team\",\n",
        "\tbackstory=(\n",
        "     \"You work at crewAI (https://crewai.com) and \"\n",
        "     \" are now working on providing \"\n",
        "\t\t \"support to {customer}, a super important customer \"\n",
        "     \" for your company.\"\n",
        "\t\t \"You need to make sure that you provide the best support!\"\n",
        "\t\t \"Make sure to provide full complete answers, \"\n",
        "     \" and make no assumptions.\"\n",
        "\t),\n",
        "\tallow_delegation=False,\n",
        "\tverbose=True,\n",
        "\tllm=hf_chat\n",
        ")"
      ],
      "metadata": {
        "id": "Egs7mJHbF9Li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   By not setting allow_delegation=False, allow_delegation takes its default value of being True.\n",
        "\n",
        "*   This means the agent can delegate its work to another agent which is better suited to do a particular task.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u_0llJA_IICM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "support_quality_assurance_agent = Agent(\n",
        "\trole=\"Support Quality Assurance Specialist\",\n",
        "\tgoal=\"Get recognition for providing the \"\n",
        "    \"best support quality assurance in your team\",\n",
        "\tbackstory=(\n",
        "\t\t\"You work at crewAI (https://crewai.com) and \"\n",
        "    \"are now working with your team \"\n",
        "\t\t\"on a request from {customer} ensuring that \"\n",
        "    \"the support representative is \"\n",
        "\t\t\"providing the best support possible.\\n\"\n",
        "\t\t\"You need to make sure that the support representative \"\n",
        "    \"is providing full\"\n",
        "\t\t\"complete answers, and make no assumptions.\"\n",
        "\t),\n",
        "\tverbose=True,\n",
        "\tllm=hf_chat\n",
        ")"
      ],
      "metadata": {
        "id": "GXD_L2mfIDAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   **Role Playing:** Both agents have been given a role, goal and backstory.\n",
        "*   **Focus:** Both agents have been prompted to get into the character of the roles they are playing.\n",
        "*   **Cooperation:** Support Quality Assurance Agent can delegate work back to the Support Agent, allowing for these agents to work together."
      ],
      "metadata": {
        "id": "ISh9xPlGJckE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools, Guardrails and Memory"
      ],
      "metadata": {
        "id": "DeAnCsnqKrrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tools**"
      ],
      "metadata": {
        "id": "ZiWAC6PHK27k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import crewAI tools"
      ],
      "metadata": {
        "id": "IM_FK-h2LhJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai_tools import SerperDevTool, \\\n",
        "                         ScrapeWebsiteTool, \\\n",
        "                         WebsiteSearchTool"
      ],
      "metadata": {
        "id": "TvitdSoHKwzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_scrape_tool = ScrapeWebsiteTool(\n",
        "    website_url=\"https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/\"\n",
        ")"
      ],
      "metadata": {
        "id": "cxjKNOqNF9OX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Different Ways to Give Agents Tools\n",
        "\n",
        "- Agent Level: The Agent can use the Tool(s) on any Task it performs.\n",
        "- Task Level: The Agent will only use the Tool(s) when performing that specific Task.\n",
        "\n",
        "**Note**: Task Tools override the Agent Tools."
      ],
      "metadata": {
        "id": "6NJhxB7bN39u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inquiry_resolution = Task(\n",
        "    description=(\n",
        "        \"{customer} just reached out with a super important ask:\\n\"\n",
        "\t      \"{inquiry}\\n\\n\"\n",
        "        \"{person} from {customer} is the one that reached out. \"\n",
        "\t\t    \"Make sure to use everything you know \"\n",
        "        \"to provide the best support possible.\"\n",
        "\t\t    \"You must strive to provide a complete \"\n",
        "        \"and accurate response to the customer's inquiry.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "\t      \"A detailed, informative response to the \"\n",
        "        \"customer's inquiry that addresses \"\n",
        "        \"all aspects of their question.\\n\"\n",
        "        \"The response should include references \"\n",
        "        \"to everything you used to find the answer, \"\n",
        "        \"including external data or solutions. \"\n",
        "        \"Ensure the answer is complete, \"\n",
        "\t\t    \"leaving no questions unanswered, and maintain a helpful and friendly \"\n",
        "\t\t    \"tone throughout.\"\n",
        "    ),\n",
        "\ttools=[docs_scrape_tool],\n",
        "    agent=support_agent,\n",
        ")"
      ],
      "metadata": {
        "id": "V-Ea-AU6F9RP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `quality_assurance_review` is not using any Tool(s)\n",
        "- Here the QA Agent will only review the work of the Support Agent"
      ],
      "metadata": {
        "id": "X08JwiJ6PDww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quality_assurance_review = Task(\n",
        "    description=(\n",
        "        \"Review the response drafted by the Senior Support Representative for {customer}'s inquiry. \"\n",
        "        \"Ensure that the answer is comprehensive, accurate, and adheres to the \"\n",
        "\t\t    \"high-quality standards expected for customer support.\\n\"\n",
        "        \"Verify that all parts of the customer's inquiry \"\n",
        "        \"have been addressed \"\n",
        "\t\t    \"thoroughly, with a helpful and friendly tone.\\n\"\n",
        "        \"Check for references and sources used to \"\n",
        "        \" find the information, \"\n",
        "\t\t    \"ensuring the response is well-supported and \"\n",
        "        \"leaves no questions unanswered.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A final, detailed, and informative response \"\n",
        "        \"ready to be sent to the customer.\\n\"\n",
        "        \"This response should fully address the \"\n",
        "        \"customer's inquiry, incorporating all \"\n",
        "\t\t    \"relevant feedback and improvements.\\n\"\n",
        "\t\t    \"Don't be too formal, we are a chill and cool company \"\n",
        "\t      \"but maintain a professional and friendly tone throughout.\"\n",
        "    ),\n",
        "    agent=support_quality_assurance_agent,\n",
        ")"
      ],
      "metadata": {
        "id": "HknjQG50F9Tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the Crew\n",
        "\n",
        "#### Memory\n",
        "- Setting `memory=True` when putting the crew together enables Memory."
      ],
      "metadata": {
        "id": "wrgiKdUPQX9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crew = Crew(\n",
        "  agents=[support_agent, support_quality_assurance_agent],\n",
        "  tasks=[inquiry_resolution, quality_assurance_review],\n",
        "  verbose=2,\n",
        "  memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "Kh_xI1nnF9WN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running the Crew\n",
        "\n",
        "**Note**: LLMs can provide different outputs for they same input, so what you get might be different than what you see in the video.\n",
        "\n",
        "#### Guardrails\n",
        "- By running the execution below, you can see that the agents and the responses are within the scope of what we expect from them."
      ],
      "metadata": {
        "id": "Lp6_p6CyQpAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\n",
        "    \"customer\": \"DeepLearningAI\",\n",
        "    \"person\": \"Kshitij Upadhyay\",\n",
        "    \"inquiry\": \"I need help with setting up a Crew \"\n",
        "               \"and kicking it off, specifically \"\n",
        "               \"how can I add memory to my crew? \"\n",
        "               \"Can you provide guidance?\"\n",
        "}\n",
        "result = crew.kickoff(inputs=inputs)"
      ],
      "metadata": {
        "id": "6AbBlwsiF9Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Display the result in Markdown**"
      ],
      "metadata": {
        "id": "AJa29-YvRRHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "Markdown(result)"
      ],
      "metadata": {
        "id": "GrZIGpFyRXBq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}