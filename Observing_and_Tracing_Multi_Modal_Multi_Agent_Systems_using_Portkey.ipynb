{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlosbkm/ADaSci-Agentic-AI-Architect-labs/blob/main/Observing_and_Tracing_Multi_Modal_Multi_Agent_Systems_using_Portkey.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Library Installation"
      ],
      "metadata": {
        "id": "IAoKi4chzxrF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6lTuPToyrJr"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain_openai langchain_community tavily-python langchain-groq groq replicate crewai crewai[tools]\n",
        "!pip install portkey-ai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### API Initialization"
      ],
      "metadata": {
        "id": "cwDIxI0xzvRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\").strip()\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = userdata.get(\"REPLICATE_API_TOKEN\").strip()\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\").strip()\n",
        "PORTKEY_API_KEY = userdata.get(\"PORTKEY_API_KEY\").strip()"
      ],
      "metadata": {
        "id": "jQnuBcy6yuo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Web Search Tool Helper Function"
      ],
      "metadata": {
        "id": "4ZPDFHlCz8LP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "def web_search_tool(question: str) -> str:\n",
        "    \"\"\"This tool is useful when we want web search for current events.\"\"\"\n",
        "    websearch = TavilySearchResults()\n",
        "    response = websearch.invoke({\"query\":question})\n",
        "    return response"
      ],
      "metadata": {
        "id": "XYtVjy6SzktW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text to Image Creation Helper Function"
      ],
      "metadata": {
        "id": "lSQGNdnz0Jje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import replicate\n",
        "def text2image(text:str) -> str:\n",
        "    \"\"\"This tool is useful when we want to generate images from textual descriptions.\"\"\"\n",
        "    output = replicate.run(\n",
        "    \"adirik/flux-cinestill:216a43b9975de9768114644bbf8cd0cba54a923c6d0f65adceaccfc9383a938f\",\n",
        "    input={\n",
        "        \"steps\": 28,\n",
        "        \"prompt\": text,\n",
        "        \"lora_url\": \"\",\n",
        "        \"control_type\": \"depth\",\n",
        "        \"control_image\": \"https://replicate.delivery/pbxt/LUSNInCegT0XwStCCJjXOojSBhPjpk2Pzj5VNjksiP9cER8A/ComfyUI_02172_.png\",\n",
        "        \"lora_strength\": 1,\n",
        "        \"output_format\": \"webp\",\n",
        "        \"guidance_scale\": 2.5,\n",
        "        \"output_quality\": 100,\n",
        "        \"negative_prompt\": \"low quality, ugly, distorted, artefacts\",\n",
        "        \"control_strength\": 0.45,\n",
        "        \"depth_preprocessor\": \"DepthAnything\",\n",
        "        \"soft_edge_preprocessor\": \"HED\",\n",
        "        \"image_to_image_strength\": 0,\n",
        "        \"return_preprocessed_image\": False\n",
        "        }\n",
        "    )\n",
        "    print(output)\n",
        "    return output[0]"
      ],
      "metadata": {
        "id": "0tgDmI6Nz6Eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text to Image Processing Helper Function"
      ],
      "metadata": {
        "id": "6qSpTzoX0SmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def image2text(image_url:str,prompt:str) -> str:\n",
        "  \"\"\"This tool is useful when we want to generate textual descriptions from images.\"\"\"\n",
        "  # Function\n",
        "  output = replicate.run(\n",
        "    \"adirik/flux-cinestill:216a43b9975de9768114644bbf8cd0cba54a923c6d0f65adceaccfc9383a938f\",\n",
        "    input={\n",
        "        \"image\": image_url,\n",
        "        \"top_p\": 1,\n",
        "        \"prompt\": prompt,\n",
        "        \"max_tokens\": 1024,\n",
        "        \"temperature\": 0.2\n",
        "    }\n",
        "  )\n",
        "  return \"\".join(output)"
      ],
      "metadata": {
        "id": "S70Bo4sv0Oro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Router Tool Setup"
      ],
      "metadata": {
        "id": "XZ-FFqNn1i_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai.tools import tool\n",
        "\n",
        "@tool(\"router tool\")\n",
        "def router_tool(question:str) -> str:\n",
        "  \"\"\"Router Function\"\"\"\n",
        "  prompt = f\"\"\"Based on the Question provide below determine the following:\n",
        "    1. Is the question directed at generating image ?\n",
        "    2. Is the question directed at describing the image ?\n",
        "    3. Is the question a generic one and needs to be answered by searching the web?\n",
        "    Question: {question}\n",
        "\n",
        "    RESPONSE INSTRUCTIONS:\n",
        "    - Answer either 1 or 2 or 3.\n",
        "    - Answer should strictly be a string.\n",
        "    - Do not provide any preamble or explanations except for 1 or 2 or 3.\n",
        "\n",
        "    OUTPUT FORMAT:\n",
        "    1\n",
        "    \"\"\"\n",
        "  response = llm.invoke(prompt).content.strip()\n",
        "  if response == \"1\":\n",
        "    return 'text2image'\n",
        "  elif response == \"3\":\n",
        "    return 'web_search'\n",
        "  else:\n",
        "    return 'image2text'"
      ],
      "metadata": {
        "id": "cFw__x9-0SMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retriever Tool"
      ],
      "metadata": {
        "id": "fCXDdI621mCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tool(\"retriver tool\")\n",
        "def retriver_tool(router_response:str,question:str,image_url:str) -> str:\n",
        "  \"\"\"Retriver Function\"\"\"\n",
        "  if router_response == 'text2image':\n",
        "    return text2image(question)\n",
        "  elif router_response == 'image2text':\n",
        "    return image2text(image_url,question)\n",
        "  else:\n",
        "    return web_search_tool(question)"
      ],
      "metadata": {
        "id": "7dxLAeq003Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Portkey Setup"
      ],
      "metadata": {
        "id": "72wdcNu12lXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL\n",
        "\n",
        "portkey_headers = createHeaders(\n",
        "    api_key = PORTKEY_API_KEY,\n",
        "    # virtual_key = \"\"\n",
        "    )\n",
        "\n",
        "# llm = ChatOpenAI(\n",
        "#     api_key=PORTKEY_API_KEY,\n",
        "#     base_url=PORTKEY_GATEWAY_URL,\n",
        "#     default_headers=portkey_headers\n",
        "#     )\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    # Set base_url to the Portkey Gateway.\n",
        "    base_url=PORTKEY_GATEWAY_URL,\n",
        "\n",
        "    # The ChatOpenAI `api_key` is used to pass the Portkey API Key.\n",
        "    # Portkey uses this key to authenticate and authorize the request\n",
        "    # before looking at the model slug for routing/provider key resolution.\n",
        "    api_key=\"dummy-key\",\n",
        "\n",
        "    # Pass the Model Catalog slug directly as the model name.\n",
        "    model=\"openai/@openai-krol-key/o4-mini-2025-04-16\",\n",
        "\n",
        "    # CRUCIAL: Pass the Portkey-specific headers. This is how Portkey\n",
        "    # receives your API key and other configurations.\n",
        "    default_headers=portkey_headers,\n",
        "\n",
        "    temperature=0.7\n",
        ")\n"
      ],
      "metadata": {
        "id": "2cwA-HOk1qQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Router Agent"
      ],
      "metadata": {
        "id": "aP8hxriq1uHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent\n",
        "Router_Agent = Agent(\n",
        "  role = 'Router',\n",
        "  goal = 'Route user question to a text to image or text to speech or web search',\n",
        "  backstory = (\n",
        "    \"You are an expert at routing a user question to a text to image or web search.\"\n",
        "    \"Use the text to image to generate images from textual descriptions.\"\n",
        "    \"Use the image to text to generate text describing the image based on the textual description.\"\n",
        "    \"Use the web search to search for current events.\"\n",
        "    \"You do not need to be stringent with the keywords in the question related to these topics. Otherwise, use web-search.\"\n",
        "  ),\n",
        "  verbose = True,\n",
        "  allow_delegation = False,\n",
        "  llm = llm,\n",
        "  tools = [router_tool],\n",
        ")"
      ],
      "metadata": {
        "id": "6EeWMLhz1vUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retriever Agent"
      ],
      "metadata": {
        "id": "hW0_lrGX2i9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Retriever_Agent = Agent(\n",
        "role = \"Retriever\",\n",
        "goal = \"Use the information retrieved from the Router to answer the question and image url provided.\",\n",
        "backstory = (\n",
        "    \"You are an assistant for directing tasks to respective agents based on the response from the Router.\"\n",
        "    \"Use the information from the Router to perform the respective task.\"\n",
        "    \"Do not provide any other explanation\"\n",
        "),\n",
        "verbose = True,\n",
        "allow_delegation = False,\n",
        "llm = llm,\n",
        "tools = [retriver_tool],\n",
        ")"
      ],
      "metadata": {
        "id": "N9MLU9_p1z6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Router Task"
      ],
      "metadata": {
        "id": "KcrPS4_-22Jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Task\n",
        "router_task = Task(\n",
        "    description=(\"Analyse the keywords in the question {question}\"\n",
        "    \"If the question {question} instructs to describe a image then use the image url {image_url} to generate a detailed and high quality images covering all the nuances secribed in the textual descriptions provided in the question {question}.\"\n",
        "    \"Based on the keywords decide whether it is eligible for a text to image or text to speech or web search.\"\n",
        "    \"Return a single word 'text2image' if it is eligible for generating images from textual description.\"\n",
        "    \"Return a single word 'image2text' if it is eligible for describing the image based on the question {question} and image url{image_url}.\"\n",
        "    \"Return a single word 'web_search' if it is eligible for web search.\"\n",
        "    \"Do not provide any other explaination.\"\n",
        "    ),\n",
        "    expected_output=(\"Give a choice 'web_search' or 'text2image' or 'image2text' based on the question {question} and image url {image_url}\"\n",
        "    \"Do not provide any preamble or explanations except for 'text2image' or 'web_search' or 'image2text'.\"),\n",
        "    agent=Router_Agent,\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZXWeMayh2sAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retriever Task"
      ],
      "metadata": {
        "id": "KM6stQEo3Bfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_task = Task(\n",
        "    description=(\n",
        "        \"Use the tool selected by the Router_Agent to either generate an image from text, \"\n",
        "        \"describe an image, or search the web. \"\n",
        "        \"When the tool generates an image (text2image), you must return ONLY the direct image URL \"\n",
        "        \"from the Replicate API response — no markdown, no explanation, no extra text. \"\n",
        "        \"If the tool describes an image (image2text), return a short plain text description. \"\n",
        "        \"If the tool performs a web search, return a concise textual summary of the results.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"If the question was to generate an image, return ONLY the direct image URL. \"\n",
        "        \"If it was to describe or search, return text only.\"\n",
        "    ),\n",
        "    agent=Router_Agent,\n",
        "    context=[router_task],\n",
        ")\n"
      ],
      "metadata": {
        "id": "OrbB5IrX2_je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Crew Setup and Initiation"
      ],
      "metadata": {
        "id": "gLXYDt723No4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Crew,Process\n",
        "crew = Crew(\n",
        "    agents=[Router_Agent,Retriever_Agent],\n",
        "    tasks=[router_task,retriever_task],\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "inputs = {\n",
        "  \"question\": \"Generate an image based upon this text: a cinematic portrait of a majestic black panther, piercing yellow eyes, moody lighting, soft bokeh, 85mm lens, deep blue jungle background\",\n",
        "  \"image_url\": \" \"\n",
        "}\n",
        "\n",
        "result = crew.kickoff(inputs=inputs)"
      ],
      "metadata": {
        "id": "k2WKp60O3I5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agent Output -- Image Link"
      ],
      "metadata": {
        "id": "vZP3Im2v7v-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"### Agent Output -- Image Link\"\"\"\n",
        "\n",
        "# retriever_task returns ONLY the image URL now\n",
        "image_url = result.final_output.strip()  # <- use the final output, not .raw\n",
        "print(image_url)  # optional: quick sanity check"
      ],
      "metadata": {
        "id": "VJIU5YMG7t7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing Image"
      ],
      "metadata": {
        "id": "YDeRm9kj73La"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# URL of the image\n",
        "image_url = result.raw\n",
        "\n",
        "# Fetch the image\n",
        "response = requests.get(image_url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Open the image using PIL\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "\n",
        "    # Display the image using matplotlib\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')  # Hide the axis\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Failed to retrieve image. Status code:\", response.status_code)"
      ],
      "metadata": {
        "id": "6565gjyT3K54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kf0x3O4m72Cj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}